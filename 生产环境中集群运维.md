### 生产环境常用配置

从Elasticsearch5开始，支持Development和Production两种运行模式，一个集群在Production Mode时，启动必须通过所有Bootstrap检测，否则会启动失败

以下包括JVM设定、集群API设定、网络设定、存储、服务器硬件、集群设置

JVM设定：

- 将内存的Xms和Xmx设置成一样，避免heap resize导致的停顿
- Xmx设置不要超过机器内存的50%（另外50%交给了Lucene，实现全文检索），单个节点内存不要超过32GB
- 关闭JVM Swapping
- 生产环境，JVM必须使用Server模式

集群API设定：

Transient Settings > Persistent Settings > Command-line settings > Config file settings

- Transient Settings在集群重启后会丢失；Persistent Settings在集群重启后不会丢失

网络设定：

- 单集群不要跨数据中心进行部署（不要使用WAN）
- 如果有多块网卡，将transport和http绑定到不同的网卡上，并且设置不同的防火墙和rule
- 节点之间的hops尽量少
- 按需为Ingest Node和Coordinating Node配置LoadBalancer

存储：

- 搜索类内存和磁盘1:16
- 日志类内存和磁盘1:50

- 使用SSD，使用本地存储
- 可以在本地指定多个path.data，以支持使用多个磁盘
- 可以在Warm节点上使用机械硬盘，但是需要关闭Concurrent Merge

服务器硬件：

- 一台机器一个节点
- 使用中等配置的机器

集群设置

- 关闭Dynamic Indexed，或者通过模板设置白名单（让某些索引可以直接添加文档而不用手动编写Mapping）

### 监控Elasticsearch集群

获取集群的状态：`GET _cluster/stats`

获取节点的状态：`GET _nodes/stats`

获取索引的状态：`GET index_name/_stats`

获取集群待处理的任务：`GET _cluster/pending_tasks`
获取所有的任务：`GET _tasks`
查看thread pool：`GET _nodes/thread_pool`
查看thread pool：`GET _cat/thread_pool?v`

将分片上Search和Fetch阶段的慢查询写入文件，需要配置相应的settings

```
PUT my_index
{
	"settings": {
		"index.search.slowlog.threshold": {
			"query.warn": "10s",
			"query.info": "3s",
			"query.dubug": "2s",
			"query.trace": "0s",,
			"fetch.warn": "1s",
			"fetch.info": "600ms",
			"fetch.debug": "400ms",
			"fetch.trace": "0s"
		}
	}
}
```

### 诊断集群的潜在问题

Elastic有提供Support Diagnostics Tool

潜在的问题：
- 节点宕机
- 副本丢失
- 集群压力过大，数据写入失败
- 资源使用情况
- 索引的合理性
- 业务操作合理性

### 集群的健康状况

集群的健康情况

- 红：至少有一个主分片没有分配
- 黄：至少有一个副本分片没有分配
- 绿：主副分片全部正常分配

一些API

- 集群的健康状况：`GET _cluster/health`
- 所有索引的健康状况：`GET _cluster/health?level=indices`
- 单个索引的健康状况：`GET _cluster/health/my_index`
- 分片级的索引健康状况：`GET _cluster/health?level=shards`
- 返回第一个未分配Shard的原因:`GET _cluster/allocation/explain`

常见问题与处理：

- 集群变红，需要检查是否有节点离线，如果有，通过重启节点就可以了
- 配置错误导致，需要修复配置
- 由于磁盘空间限制，分片规则引发的，通过调整规则或者增加节点数量可以解决
- 一个节点离开集群期间，有索引被删除了，当这个节点重新返回集群的时候，会导致dangling_index_imported的问题，健康状况为red。此时只需要再执行一次索引删除的操作就可以了
- 对于创建，增加副本等操作，集群会有短暂的不健康，所以监控和报警需要设置一定的延时

### 提高集群的写性能

- 客户端：通过性能测试，确定一次bulk的最佳文档数量；多线程，需要观察是否有HTTP 429返回，实现Retry以及线程数量的自动调节
- 服务端：
  - 降低IO操作：使用Elasticsearch自动生成文档ID；增加refresh interval
  - 降低CPU和存储开销：减少不必要的分词；避免不必须要的doc_values；文档的字段尽量保证相同的顺序，可以提高文档的压缩率
  - 调整bulk线程池和队列
  - 做到写入和分片的负载均衡，实现水平扩展

关闭无关的功能：

- 不需要索引的时候，将index设置为false
- 不需要算分的时候，norms=false
- 对于指标型数据，关闭_source，减少IO
- Index_options控制哪些内容会被添加到倒排索引中
- 不要对字符串使用默认的Dynamic Mapping，字段数量过多，会对性能产生影响

针对性能的取舍

- 牺牲可靠性：将副本分片数设置为0，写入完毕后调整回去
- 牺牲可靠性：修改translog设置
  - index.translog.durability：默认是request，每次请求的时候都会落盘。设置成async，异步写入
  - index.translog.sync_interval：设置为60s
  - index.translog.flush_threshold_size：默认512MB，增大数值
- 牺牲搜索的实时性：降低refresh的频率
  - 增加refresh_interval的数值，默认是1s
  - 增加indices.memory.index_buffer_size，默认是10%

Bulk，线程池和队列大小

- 客户端
  - 一个bulk数据量控制在5-15MB
  - bulk请求超时需要设置60s以上
  - 尽量将数据轮询打到不同的节点
- 服务端
  - 使用固定大小的线程池来配置，来不及处理的放入队列，线程数量为CPU核心数+1
  - 队列大小适当，不要过大导致GC

### 提高集群读性能

- 尽量Denormalize数据，Nested类型的数据，查询速度会慢几倍，而Parent/Child关系，查询速度会慢几百倍
- 尽量将数据提前计算好，可以使用Ingest Pipeline，计算并写入文档的字段中，避免在查询的时候使用script
- 尽量使用Filter Context，可以利用缓存机制，减少不必要的算分
- 结合profile，explain API分析慢查询的问题，持续优化数据模型
- 严禁使用*开头的通配符Terms查询
- 优化分片：避免过多的分片（一个查询需要访问所有的分片），对于基于时间序列的索引，将只读的索引进行force merge，减少segment数量；控制一个分片的大小（搜索类20GB，日志类40GB）；

### 压力测试

压力测试的步骤：

1. 测试计划（确定测试场景和测试数据集）
2. 脚本开发
3. 测试环境搭建（不同的软硬件配置）& 运行测试
4. 分析对比测试报告

#### Elastic Rally

官方开源的，基于Pythoin3的压力测试工具，https://github.com/elastic/rally

Tournament（测试目标），Track（测试数据和测试场景与策略），Car（不同配置的Elasticsearch实例）

```
运行（由于需要下载测试数据集，过程比较慢）：`esrally --distribution-version=7.1.0`
运行1000条测试数据：`esrally --distribution-version=7.1.0 --test-mode`
```

- 比较不同的版本性能

```
esrally race --distribution-version=6.0.0 --track=nyc_taxis --challenge=append-no-conflicts -user-tag="version:6.0.0"
esrally race --distribution-version=7.1.0 --track=nyc_taxis --challenge=append-no-conflicts -user-tag="version:7.1.0"
比较结果
esrally list races
esrally compare --baseline=[6.0.0 race] --contender=[7.1.0 race]
```

- 比较不同Mapping的性能

```
esrally race --distribution-version=7.1.0 --track=nyc_taxis --challenge=append-no-conflicts -user-tag="enableSource:true" --include-tasks="type:index"
修改benchmarks/tracks/default/nyc_taxis/mappings.json, 修改_source.enabled:false
esrally race --distribution-version=7.1.0 --track=nyc_taxis --challenge=append-no-conflicts -user-tag="enableSource:false" --include-tasks="type:index"
比较结果
esrally compare --baseline=[enableAll race] --contender=[disableAll race]
```

- 测试现有集群的性能

```
esrally race --pipeline=benchmark-only --target-hosts=127.0.0.1:9200 --track=geonames --challenge=append-no-conflicts
```

### Segement Merge

- Elasticsearch和Lucene会自动进行merge操作

- merge的操作比较重，需要优化

- 优化点：

  - 降低Segemnt产生的数量/频率（增大refresh interval；增大indices.memory.index_buffer_size）

  - 降低最大分段大小，避免较大的分段继续参与merge（index.merge.policy.segments_per_tier，越小需要越多的合并操作；index.merge.policy.max_merged_segment，超过这个大小，就不再参与后续的合并操作）

  - 当Index没有写入操作的时候，执行force merge，希望最终force merge成1个最好，但是这个操作会占用大量的资源，如果不能在业务高峰期之前弄完，那么需要考虑增加最终的分段数（增大Shard，或者减小index.merge.policy.max_merged_segment）

    - ```	
      POST my_index/_forcemerge?max_num_segments=1
      GET _cat/segments/my_index?v
      ```

### 缓存与内存使用

Elasticsearch的缓存有三大类：

- Node Query Cache：每个节点都有这个，节点上的所有分片共享，只缓存Filter Context的内容；使用LRU算法
- Fielddata Cache：除了Text类型默认都使用doc_values，节省了内存。Text类型需要打开fielddata才能进行聚合和排序，才会缓存。Aggregation的Global ordinals也保存在这儿
- Shard Query Cache：缓存每个分片上的查询结果，只会缓存设置了size=0的查询结果，不会缓存hits，一般缓存Aggregations和Suggestions；使用LRU算法；将整个JSON查询串作为Key

缓存失效：

- Node Query Cache：Segment被合并后，缓存失效
- Shard Query Cache：当分片Refresh，也即Shard的数据更新的时候，缓存失效
- Fielddata Cache：Segment被合并后，缓存失效

#### 一些常见的内存问题

Segment数量过多，导致Full GC

- 现象：集群整体响应缓慢，也没有特别多的数据读写，但是发现节点在持续金进行Full GC
- 分析：查看Elasticsearch的内存使用，发现segemtns.memory占用很大空间
- 解决：通过force merge，把Segment合并为1个
- 建议：对于不在更新的索引，设置为只读，同时进行force merge操作。如果问题仍然存在，那么需要考虑进行扩容。另外，对索引进行force merge，还可以减少global_ordinals数据结构的构建，减少Fielddata Cache的开销

Field data Cache过大，导致Full GC

- 现象：集群整体响应缓慢，也没有特别多的数据读写，但是发现节点在持续金进行Full GC
- 分析：查看Elasticsearch的内存使用，发现fielddata.memory.size占用很大空间。同时，数据不存在写入和更新，也执行过segment merge
- 解决：将indices.fielddata.cache.size设小，重启节点，堆内存回复正常
- 建议：field data cache的构建比较重，Elasticsearch不会主动释放，所以一般将这个大小设置小一点。如果确实要大，需要增加节点

复杂的嵌套聚合，导致Full GC

- 现象：节点响应缓慢，持续进行Full GC
- 分析：导出Dump文件，发现内存中有大量的Bucket对象，查看日志，发现复杂的嵌套聚合
- 解决：优化聚合查询
- 建议：对大数据集进行嵌套聚合，需要很大的堆内存。如果业务确实需要，需要扩容。同时，为了避免操作影响整个集群，需要设置Circuit Breaker和search.max_buckets的数值

#### Circuit Breaker

- 避免不合理操作引发的OOM，包含多个断路器，每个断路器可以指定内存使用的限制
- 通过`GET /_nodes/stats/breaker?`查看断路器的情况，当tripped大于0，说明有熔断过，limit size与 estimated size越接近，越有可能引发熔断

### 一些运维的建议

#### 集群的生命周期管理

- 预上线的时候评估用户的需求和使用场景、数据建模、容量规划、选择合适的集群架构、性能测试
- 上线后
  - 监控流量，定期检查潜在的问题
  - 对索引进行优化，检查是否存在不均衡而导致部分节点过热
  - 定期数据备份、滚动升级

#### 部署

- 根据使用场景，选择合适的部署方式，选择合适的硬件配置
- 部署要考虑反亲和性，尽量进机器分散在不同的机架上，善用shard filtering进行配置

#### 使用

- 设置slowlogs，发现性能不好，甚至是使用错误的pattern

- 定期进行集群备份

- 定期更新到新版本

- 当一个数据节点上有过多的Hot Shards，手动分配分片到特定的节点

  - ```
    POST _cluster/reroute
    {
    	"commands": [
    		{
    			"move": {
    				"index": "index_name",
    				"shard": 0,
    				"from_node": "node_name1",
    				"to_node": "node_name2"
    			}
    		}
    	]
    }
    ```

- 从集群中移除一个节点，从而能够对节点进行维护

  - ```
    PUT _cluster/settings
    {
    	"transient": {
    		"cluster.routing.allocation.exclude._ip": "the_ip_of_your_node"
    	}
    }
    ```

- 控制Allocation和Recovery的速率保障集群整体的正常运行

- 清空节点上的缓存，避免集群出现OOM，但是会影响集群的性能，`POST cache/clear`

- 当搜索的响应时间过长，看到有reject指标的增加，可以增加`threadpool.search.queue_size:2000`

- 设置各类Circuit Breaker，避免OOM的发生

#### Rolling Update v.s Full Cluster Restart

Rolling Update：没有Downtime

Full Cluster Restart：集群在更新期间不可用，但是升级速度更快

##### Full Cluster Restart步骤

1. 停止索引数据，同时备份集群
2. 关闭Shard Allocation，`cluster.routing.allocation.enable:primaries`

3. 执行Synced Flush，`POST _flush/synced`
4. 关闭并更新所有节点
5. 先将所有的Master节点打开，再运行其他节点
6. 等集群变黄后打开Shard Allocation